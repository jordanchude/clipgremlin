CLIPGREMLIN â€“ DEVELOPER-READY SPECIFICATION
==========================================

OVERVIEW
â€¢ ClipGremlin is a stateless Python bot that joins a Twitch channel, transcribes the live audio with OpenAI Whisper-Turbo, andâ€”after 60 seconds of total chat silenceâ€”drops exactly one mischievous PG-13 prompt in the same language the streamer is speaking.  
  â€“ Twitchâ€™s unverified-bot cap is 20 chat messages per 30 seconds; exceeding it mutes the bot for 30 minutes. :contentReference[oaicite:0]{index=0}  
  â€“ The spoken-language code comes directly from the Whisper JSON response. :contentReference[oaicite:1]{index=1}  
â€¢ Broadcaster or moderator can mute / un-mute the bot with `!gremlin pause` and `!gremlin resume`; the bot replies â€œGremlin muted ğŸ˜¶â€ or â€œGremlin unleashed ğŸ˜ˆâ€ as confirmation.  
â€¢ Workers spin up only while the channel is live, triggered by Twitch EventSubâ€™s `stream.online` webhook, and shut down on `stream.offline`, saving compute costs. :contentReference[oaicite:2]{index=2}  

FUNCTIONAL REQUIREMENTS
1. On receiving a `stream.online` EventSub notification, start a Fargate task and join the IRC channel as **ClipGremlin**. :contentReference[oaicite:3]{index=3}  
2. Use `ffmpeg` to pull the low-latency HLS playlist, down-mix to mono 16 kHz WAV, and cut â‰¤10 second chunks (always < 25 MB per Whisper request). :contentReference[oaicite:4]{index=4}  
3. Send each chunk to Whisper-Turbo; typical end-to-end model latency is ~300 ms. :contentReference[oaicite:5]{index=5}  
4. Maintain a rolling 60-second window of incoming chat messages (in RAM).  
5. When the window shows **zero** messages for 60 seconds, ask GPT-3.5-Turbo for a one-line, PG-13, ToS-safe â€œtrollâ€ question that fits the latest transcript snippet.  
6. Run the candidate text through Twitchâ€™s *Check AutoMod Status* endpoint; if â€œALLOWâ€, post it; if â€œDENYâ€, drop it silently. :contentReference[oaicite:6]{index=6}  
7. Accept `!gremlin pause` and `!gremlin resume` commands from broadcaster or moderators only (verified via IRC message tags). :contentReference[oaicite:7]{index=7}  
8. On `stream.offline`, terminate the Fargate task; no state is persisted.

NON-FUNCTIONAL REQUIREMENTS
â€¢ Cold-start latency: the first prompt must appear no later than 90 seconds after `stream.online`.  
  â€“ zstd-compressed container layers shorten Fargate startup times significantly. :contentReference[oaicite:8]{index=8}  
â€¢ Runtime latency: microphone-to-prompt path must stay under 10 seconds (â‰ˆ2 s HLS + â‰¤0.3 s Whisper + GPT call).  
â€¢ Statelessness: no database, cache, or disk storage; all runtime data lives in RAM.  
â€¢ Resilience: if the task crashes, CloudWatch alarms and EventBridge rules relaunch the definition automatically. :contentReference[oaicite:9]{index=9}  

ARCHITECTURE (ASCII)
Twitch EventSub â”€â”€â–¶ AWS Lambda (webhook validator)  
                      â”‚  
                      â–¼  
                AWS Fargate Task  
                â”œâ”€ ffmpeg (HLS â†’ WAV)  
                â”œâ”€ Whisper-Turbo (speech-to-text)  
                â”œâ”€ GPT-3.5-Turbo (prompt craft)  
                â””â”€ IRC / Helix POST (chat message)  
                      â–²  
                      â”‚ AutoMod check  
                      â–¼  
                 Twitch Chat Server  

KEY IMPLEMENTATION DETAILS
â€¢ Container image: `python:3.11-slim` (~120 MB compressed) plus static `ffmpeg`.  
â€¢ Libraries: `openai`, `twitchio`, `aiohttp`, `uvloop`.  
â€¢ Secrets: Twitch OAuth client ID/secret and OpenAI key stored in AWS Secrets Manager.  
â€¢ Billing: Fargate charges per-second with a one-minute minimum, so idle time costs $0. :contentReference[oaicite:10]{index=10}  
â€¢ Username colour: `/color Green`â€”a preset shade available to any account; no Prime or hex code required. :contentReference[oaicite:11]{index=11}  
â€¢ Verified-bot badge (future): raises the cap from 20 to 100 messages per 30 seconds. :contentReference[oaicite:12]{index=12}  

DATA HANDLING
â€¢ HLS AAC segments and WAV chunks are discarded immediately after processing.  
â€¢ Whisper JSON and GPT payloads are kept in memory only long enough to complete a prompt (<1 minute).  
â€¢ No personally identifiable information is stored or logged.  

ERROR-HANDLING STRATEGIES
â€¢ Whisper request >25 MB â†’ chunker already enforces â‰¤10 s slices; log and skip.  
â€¢ GPT time-out â†’ exponential back-off (max 2 retries) then abandon that prompt cycle.  
â€¢ Rate-limit over-run â†’ delay sends until the rolling 30-second window drops below 20 messages. :contentReference[oaicite:13]{index=13}  
â€¢ AutoMod â€œBLOCKâ€ â†’ do not post alternate wording; wait for next silence event.  
â€¢ Fargate task crash â†’ CloudWatch + EventBridge relaunch same task definition. :contentReference[oaicite:14]{index=14}  

TESTING PLAN
â€¢ Unit tests: silence-detector edge cases; command-parser privilege checks; AutoMod stub.  
â€¢ Integration tests: local sandbox with Twitch IRC test server and prerecorded VOD; verify <10 s latency from audio to prompt.  
â€¢ Load tests: 8-hour soak run; ensure memory <200 MiB and message rate never exceeds 20/30 s.  
â€¢ Chaos tests: inject Whisper 500 errors; confirm retries then skip.  

OPERATIONAL CHECKLIST
1. Register Twitch account â€œClipGremlinâ€ and set `/color Green`. :contentReference[oaicite:15]{index=15}  
2. Create EventSub webhooks for `stream.online` and `stream.offline`. :contentReference[oaicite:16]{index=16}  
3. Store secrets in AWS Secrets Manager.  
4. Build zstd-compressed image; push to ECR. :contentReference[oaicite:17]{index=17}  
5. Deploy Fargate task (0.25 vCPU / 512 MiB) via CloudFormation or Terraform.  
6. Configure CloudWatch alarms for task failure and API quota usage.  

FUTURE EXTENSIONS
â€¢ Apply for verified-bot badge to unlock 100 msgs / 30 s. :contentReference[oaicite:18]{index=18}  
â€¢ Persist prompt logs to DynamoDB for analytics.  
â€¢ Enable automatic clip creation via Helix `POST /helix/clips` when streamers opt-in. :contentReference[oaicite:19]{index=19}  
â€¢ Swap Fargate for AWS Lambda SnapStart if sub-20 s cold starts ever become critical.
